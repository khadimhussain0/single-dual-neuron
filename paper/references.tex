\section{References}

\begin{enumerate}
\item A. Dosovitskiy, L. Beyer, A. Kolesnikov, \textit{et al.}, ``An Image is Worth 16$\times$16 Words: Transformers for Image Recognition at Scale,'' \textit{arXiv preprint} arXiv:2010.11929, 2020.

\item Y. Wang, Y. Deng, Y. Zheng, P. Chattopadhyay, and L. Wang, ``Vision Transformers for Image Classification: A Comparative Survey,'' \textit{Technologies}, vol. 13, no. 1, p. 32, 2025.

\item K. Han, Y. Wang, Q. Tian, \textit{et al.}, ``A Survey on Vision Transformer,'' \textit{IEEE TPAMI}, vol. 45, no. 1, pp. 87--110, 2023.

\item S. Yang, C. Zhang, and W. Wu, ``Binary Output Layer of Feedforward Neural Networks for Solving Multi-Class Classification Problems,'' \textit{IEEE Access}, vol. 6, pp. 80297--80306, 2018.

\item K. Tyagi, C. Rane, K. Vaidya, \textit{et al.}, ``Making Sigmoid-MSE Great Again: Output Reset Challenges Softmax Cross-Entropy in Neural Network Classification,'' \textit{arXiv preprint} arXiv:2411.11213, 2024.

\item R. Memisevic, C. Zach, M. Pollefeys, and P. Hebert, ``Gated Softmax Classification,'' \textit{Advances in Neural Information Processing Systems}, vol. 23, 2010.

\item S. Eger, G. Yogatama, and I. Dyer, ``Is it Time to Swish? Comparing Deep Learning Activation Functions across NLP Tasks,'' \textit{arXiv preprint} arXiv:1901.02671, 2019.

\item A. D. Jagtap and G. E. Karniadakis, ``How Important Are Activation Functions in Regression and Classification? A Survey, Performance Comparison, and Future Directions,'' \textit{arXiv preprint} arXiv:2209.02681, 2022.

\item B. Asadi and H. Jiang, ``On Approximation Capabilities of ReLU Activation and Softmax Output Layer in Neural Networks,'' \textit{arXiv preprint} arXiv:2002.04060, 2020.

\item S. Kumar and A. Kumar, ``Activation Functions in Deep Learning: A Comprehensive Survey and Benchmark,'' \textit{arXiv preprint} arXiv:2109.14545, 2021.

\item H. Touvron, M. Cord, A. Sablayrolles, \textit{et al.}, ``Training Data-Efficient Image Transformers \& Distillation through Attention,'' \textit{Proc. 38th ICML}, pp. 10347--10357, 2021.

\item M. Khalil, A. Khalil, and A. Ngom, ``A Comprehensive Study of Vision Transformers in Image Classification Tasks,'' \textit{arXiv preprint} arXiv:2312.01232, 2023.

\item S. Yang, C. Zhang, Y. Bao, J. Yang, and W. Wu, ``Binary Output Layer of Extreme Learning Machine for Solving Multi-Class Classification Problems,'' \textit{Neural Computing and Applications}, vol. 32, no. 19, pp. 15297--15310, 2020.

\item M. Klimo, P. Luk\'{a}\v{c}, and P. Tar\'{a}bek, ``Deep Neural Networks Classification via Binary Error-Detecting Output Codes,'' \textit{Applied Sciences}, vol. 11, no. 8, p. 3563, 2021.

\item S. Maharjan, A. Alsadoon, P. W. C. Prasad, and A. K. Singh, ``A Novel Enhanced Softmax Loss Function for Brain Tumour Detection Using Deep Learning,'' \textit{Neural Computing and Applications}, vol. 32, no. 19, pp. 15283--15296, 2020.

\item R. Hu, B. Tian, S. Yin, and S. Wei, ``Efficient Hardware Architecture of Softmax Layer in Deep Neural Network,'' in \textit{Proc. IEEE Asia Pacific Conf. on Circuits and Systems (APCCAS)}, 2018, pp. 468--471.

\item S. Khan, M. Naseer, H. Hayat, S. W. Zamir, F. S. Khan, and M. Shah, ``Transformers in Vision: A Survey,'' \textit{ACM Computing Surveys}, vol. 54, no. 10s, pp. 1--41, 2022.

\item Z. Liu, Y. Lin, Y. Cao, \textit{et al.}, ``Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows,'' in \textit{Proc. IEEE/CVF Int. Conf. on Computer Vision (ICCV)}, 2021.

\item X. Chu, Z. Tian, B. Zhang, \textit{et al.}, ``Twins: Revisiting the Design of Spatial Attention in Vision Transformers,'' \textit{Advances in Neural Information Processing Systems}, vol. 34, 2021.

\item A. Vaswani, N. Shazeer, N. Parmar, \textit{et al.}, ``Attention Is All You Need,'' \textit{Advances in Neural Information Processing Systems}, vol. 30, 2017.

\item Y. Wu, Y. Xiao, H. Tang, \textit{et al.}, ``Visual Transformers: Token-based Image Representation and Processing for Computer Vision,'' \textit{arXiv preprint} arXiv:2006.03677, 2020.

\item J. Maur\'{i}cio, A. de Carvalho, J. R. S. Tavares, and P. Martins, ``Comparing Vision Transformers and Convolutional Neural Networks for Image Classification: A Literature Review,'' \textit{Applied Sciences}, vol. 13, no. 9, p. 5521, 2023.

\item Y. Huo, K. Jin, J. Cai, H. Xiong, and J. Pang, ``Vision Transformer (ViT)-Based Applications in Image Classification,'' in \textit{Proc. IEEE 9th Int. Conf. on Big Data Security on Cloud}, 2023.

\item Z. Qi, Y. Zhang, R. Li, \textit{et al.}, ``Privacy-Preserving Image Classification Using Vision Transformer,'' \textit{arXiv preprint} arXiv:2205.12041, 2022.

\item H. Zheng, Z. Yang, W. Liu, J. Liang, and Y. Li, ``Improving Deep Neural Networks Using Softplus Units,'' in \textit{Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)}, 2015, pp. 1681--1685.

\item D. Pedamonti, ``Comparison of Non-Linear Activation Functions for Deep Neural Networks on MNIST Classification Task,'' \textit{arXiv preprint} arXiv:1804.02763, 2018.

\item G. Alcantara, ``Empirical Analysis of Non-Linear Activation Functions for Deep Neural Networks in Classification Tasks,'' \textit{arXiv preprint} arXiv:1710.11272, 2017.

\item S. Sharma, S. Sharma, and A. Athaiya, ``Activation Functions in Neural Networks,'' \textit{International Journal of Engineering and Applied Sciences}, vol. 4, no. 12, pp. 310--316, 2017.
\end{enumerate}
